{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# 解压 MNIST 图像文件\n",
        "def extract_mnist_images(file_path, save_dir):\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
        "        data = data.reshape(-1, 28, 28)\n",
        "\n",
        "    # 保存为 PNG 图像\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for i, image in enumerate(data):\n",
        "        im = Image.fromarray(image)\n",
        "        im.save(os.path.join(save_dir, f'image_{i:05d}.png'))\n",
        "\n",
        "# 设置文件路径和保存目录\n",
        "mnist_images_path = '/content/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz'\n",
        "save_directory = 'data/mnist_images'\n",
        "\n",
        "# 解压并保存为 PNG\n",
        "extract_mnist_images(mnist_images_path, save_directory)\n"
      ],
      "metadata": {
        "id": "SskYfSanF9_K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置文件路径和保存目录\n",
        "mnist_images_path = '/content/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz'\n",
        "save_directory = 'data/mnist_labels'\n",
        "\n",
        "# 解压并保存为 PNG\n",
        "extract_mnist_images(mnist_images_path, save_directory)"
      ],
      "metadata": {
        "id": "YNchEkTXHIGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def extract_mnist_labels(file_path, save_path):\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        data = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    # 保存为 numpy 数组\n",
        "    np.save(save_path, data)\n",
        "\n",
        "# 设置文件路径和保存路径\n",
        "mnist_labels_path = '/content/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz'\n",
        "save_path = 'data/mnist_labels'\n",
        "\n",
        "# 解压并保存为 numpy 数组\n",
        "extract_mnist_labels(mnist_labels_path, save_path)\n"
      ],
      "metadata": {
        "id": "Y3K5LWGoHb7o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 读取 npy 文件\n",
        "file_path = '/content/data/mnist_labels.npy'\n",
        "data = np.load(file_path)\n",
        "\n",
        "# 保存为文本文件\n",
        "text_file_path = '/content/data/mnist_labels.txt'\n",
        "np.savetxt(text_file_path, data, fmt='%s')\n"
      ],
      "metadata": {
        "id": "a5bXUE4AKR8Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images_folder, labels_path, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.labels = np.load(labels_path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_folder, f'image_{idx:05d}.png')\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(int(self.labels[idx]))\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# 设置数据集路径和转换\n",
        "images_folder_path = '/content/data/mnist_images'\n",
        "labels_path = '/content/data/mnist_labels.npy'\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# 创建自定义数据集\n",
        "custom_dataset = CustomDataset(images_folder_path, labels_path, transform)\n",
        "\n",
        "# 创建 DataLoader\n",
        "batch_size = 64\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 现在，你可以使用 dataloader 迭代数据集进行训练\n",
        "for batch_data, batch_labels in dataloader:\n",
        "  print(\"batch_labels \", batch_labels)\n",
        "    # 在这里进行你的训练操作\n",
        "    # pass\n"
      ],
      "metadata": {
        "id": "M-KSmR98Ig12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "from time import time\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "class Opt(object):\n",
        "    dim = 10\n",
        "    n_epochs = 200\n",
        "    batch_size = dim*dim\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    n_cpu = 1\n",
        "    latent_dim = 100\n",
        "    img_size = 28\n",
        "    channels = 1\n",
        "    sample_interval = 400\n",
        "opt = Opt()\n",
        "\n",
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "# generator = Generator()\n",
        "# discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    # generator.cuda()\n",
        "    # discriminator.cuda()\n",
        "    bce_loss.cuda()\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "wrAkc6RhwTHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGdn9lMBfbuz"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "from time import time\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images_folder, labels_path, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.labels = np.load(labels_path)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_folder, f'image_{idx:05d}.png')\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(int(self.labels[idx]))\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class Opt(object):\n",
        "    dim = 10\n",
        "    n_epochs = 200\n",
        "    batch_size = dim*dim\n",
        "    lr = 0.0002\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "    n_cpu = 1\n",
        "    latent_dim = 100\n",
        "    img_size = 28\n",
        "    channels = 1\n",
        "    sample_interval = 400\n",
        "opt = Opt()\n",
        "\n",
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "        self.model = nn.Sequential(\n",
        "            *block(opt.latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *img_shape)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    bce_loss.cuda()\n",
        "\n",
        "# # Configure data loader\n",
        "# os.makedirs(\"data/mnist\", exist_ok=True)\n",
        "# dataloader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST(\n",
        "#         \"data/mnist\",\n",
        "#         train=True,\n",
        "#         download=True,\n",
        "#         transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
        "#     ),\n",
        "#     batch_size=opt.batch_size,\n",
        "#     shuffle=True,\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# 设置数据集路径和转换\n",
        "images_folder_path = '/content/data/mnist_images'\n",
        "labels_path = '/content/data/mnist_labels.npy'\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# 创建自定义数据集\n",
        "custom_dataset = CustomDataset(images_folder_path, labels_path, transform)\n",
        "\n",
        "# 创建 DataLoader\n",
        "batch_size = 64\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "saved_imgs = []\n",
        "for epoch in range(opt.n_epochs):\n",
        "    print('Epoch ' + str(epoch) + ' training...' , end=' ')\n",
        "    start = time()\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "        #  train Generator\n",
        "        generator_optimizer.zero_grad()\n",
        "        # sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "        # generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "        # loss measures generator's ability to fool the discriminator:\n",
        "        # for the generated images, the generator wants the discriminator to think they're real (1)\n",
        "        # so if the discriminator(gen_imgs) == real == 1, then the generator is doing a good job, there is no loss\n",
        "        generator_loss = bce_loss(discriminator(gen_imgs), real)\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        # train Discriminator\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        # loss measure discriminator's ability to classify real from generated samples:\n",
        "        real_loss = bce_loss(discriminator(real_imgs),         real)\n",
        "        fake_loss = bce_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        discriminator_loss = (real_loss + fake_loss) / 2\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "    end = time()\n",
        "    elapsed = end - start\n",
        "    print('done, took %.1f seconds.' % elapsed)\n",
        "    grid = torchvision.utils.make_grid(gen_imgs.data.cpu(), nrow=opt.dim)\n",
        "    img = (np.transpose(grid.detach().numpy(), (1, 2 ,0)) * 255).astype(np.uint8)\n",
        "    saved_imgs.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WhpmvokgLPa"
      },
      "source": [
        "img_indexes = [0, 4, 9, 49, 99, 149, 199]\n",
        "for i in img_indexes:\n",
        "    plt.figure(figsize = (opt.dim, opt.dim))\n",
        "    plt.imshow(saved_imgs[i], interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbgSgJ3l_C8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}