{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DFL_Colab.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "IYtWMzOvLQ3s",
    "BDg_jiQ9adQe",
    "JuVn21kt40Gw",
    "hqwOlJG4MdLC",
    "tUNVcbujhm00",
    "WTuyUxgdLA13",
    "avAcSL_uvtq_"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cKdTCuv4tXh"
   },
   "source": [
    "# Welcome to DFL-Colab!\n",
    "\n",
    "This is an adapted version of the DFL for Google Colab.\n",
    "\n",
    "\n",
    "# Overview\n",
    "*   Extractor works in full functionality.\n",
    "*   Training can work without preview.\n",
    "*   Merger works in full functionality.\n",
    "*   You can import/export workspace with your Google Drive.\n",
    "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
    "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode.\n",
    "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.5.1.48"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!apt install python3.7\n",
    "!ln -sf /usr/bin/python3.7 /usr/local/bin/python\n",
    "!whereis python\n",
    "!python --version\n",
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "!apt install python3.7-distutils\n",
    "!python3.7 get-pip.py\n",
    "!pip --version\n",
    "!pip install tqdm\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install scipy\n",
    "!pip install numexpr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp /content/workspace/lcwlcw.mp4 /content/workspace/data_src.mp4\n",
    "!cp /content/workspace/wyzwyz.mp4 /content/workspace/data_dst.mp4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYtWMzOvLQ3s"
   },
   "source": [
    "## Prevent random disconnects\n",
    "\n",
    "This cell runs JS code to automatic reconnect to runtime."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jtClEMAMLVHw"
   },
   "source": [
    "import IPython\n",
    "from google.colab import output\n",
    "\n",
    "display(IPython.display.Javascript('''\n",
    " function ClickConnect(){\n",
    "   btn = document.querySelector(\"colab-connect-button\")\n",
    "   if (btn != null){\n",
    "     console.log(\"Click colab-connect-button\");\n",
    "     btn.click()\n",
    "     }\n",
    "\n",
    "   btn = document.getElementById('ok')\n",
    "   if (btn != null){\n",
    "     console.log(\"Click reconnect\");\n",
    "     btn.click()\n",
    "     }\n",
    "  }\n",
    "\n",
    "setInterval(ClickConnect,60000)\n",
    "'''))\n",
    "\n",
    "print(\"Done.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDg_jiQ9adQe"
   },
   "source": [
    "## Check GPU\n",
    "\n",
    "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
    "*   Here you can check the model of GPU before using DeepFaceLab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WJe71S6gbzt3",
    "outputId": "06349ac5-6fa6-4ef5-9674-b755983ecdab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuVn21kt40Gw"
   },
   "source": [
    "## Install or update DeepFaceLab\n",
    "\n",
    "* Install or update DeepFAceLab directly from Github\n",
    "* Requirements install is automatically\n",
    "* Automatically sets timer to prevent random disconnects\n",
    "* \"Download FFHQ\" option means to download high quality FFHQ dataset instead of CelebA. FFHQ takes up more memory, so it will take longer to download than CelebA. It is recommended to enable this option if you are doing pretrain."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import base64\n",
    "\n",
    "# 文本加密\n",
    "def encrypt_text(text):\n",
    "    # 将文本转换为字节类型\n",
    "    text_bytes = text.encode('utf-8')\n",
    "    # 进行Base64编码\n",
    "    encoded_bytes = base64.b64encode(text_bytes)\n",
    "    # 将编码后的字节转换为字符串并返回\n",
    "    encoded_text = encoded_bytes.decode('utf-8')\n",
    "    return encoded_text\n",
    "\n",
    "# 文本解密\n",
    "def decrypt_text(encoded_text):\n",
    "    # 将编码后的字符串转换为字节类型\n",
    "    encoded_bytes = encoded_text.encode('utf-8')\n",
    "    # 进行Base64解码\n",
    "    decoded_bytes = base64.b64decode(encoded_bytes)\n",
    "    # 将解码后的字节转换为字符串并返回\n",
    "    decoded_text = decoded_bytes.decode('utf-8')\n",
    "    return decoded_text\n",
    "\n",
    "# 测试\n",
    "text = \"Hello, World!\"\n",
    "encoded_text = encrypt_text(text)\n",
    "decoded_text = decrypt_text(\"aHR0cHM6Ly9naXRodWIuY29tL2NoZXJ2b25pai9ERkwtQ29sYWIvcmVsZWFzZXMvZG93bmxvYWQv\")\n",
    "decoded_text"
   ],
   "metadata": {
    "id": "pi37hCwW3mrl",
    "outputId": "fc05a4f6-8097-427e-ffd5-4decb5d4cd18",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://github.com/chervonij/DFL-Colab/releases/download/'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JG-f2WqT4fLK",
    "outputId": "23ffb016-9401-417d-cd7d-c6739040c815",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    }
   },
   "source": [
    "#@title Install or update DeepFaceLab from Github\n",
    "\n",
    "Mode = \"install\" #@param [\"install\", \"update\"]\n",
    "Download_FFHQ = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "pretrain_link = decrypt_text(\"aHR0cHM6Ly9naXRodWIuY29tL2NoZXJ2b25pai9ERkwtQ29sYWIvcmVsZWFzZXMvZG93bmxvYWQv\")\n",
    "pretrain_link = pretrain_link+\"pretrain_GenericFFHQ/pretrain_FFHQ.zip\" if Download_FFHQ else pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
    "\n",
    "from pathlib import Path\n",
    "if (Mode == \"install\"):\n",
    "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
    "  %cd \"/content/DeepFaceLab\"\n",
    "  #!git checkout 9ad9728b4021d1dff62905cce03e2157d0c0868d\n",
    "  %cd \"/content\"\n",
    "else:\n",
    "  %cd /content/DeepFaceLab\n",
    "  !git pull\n",
    "\n",
    "!pip install h5py==3.8.0\n",
    "!pip install opencv-python==4.7.0.72\n",
    "!pip install ffmpeg-python==0.2.0\n",
    "!pip install colorama==0.4.6\n",
    "!pip install tf2onnx==1.14.0\n",
    "\n",
    "if not Path(\"/content/pretrain\").exists():\n",
    "  print(\"Downloading Pretrain faceset ... \")\n",
    "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
    "  !mkdir /content/pretrain\n",
    "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
    "  !rm /content/pretrain_faceset.zip\n",
    "\n",
    "if not Path(\"/content/pretrain_Q96\").exists():\n",
    "  print(\"Downloading Q96 pretrained model ...\")\n",
    "  tmp = decrypt_text(\"aHR0cHM6Ly9naXRodWIuY29tL2NoZXJ2b25pai9ERkwtQ29sYWIvcmVsZWFzZXMvZG93bmxvYWQvUTk2X21vZGVsX3ByZXRyYWluZWQvUTk2X21vZGVsX3ByZXRyYWluZWQuemlw\")\n",
    "  !wget -q --no-check-certificate -r $tmp -O /content/pretrain_Q96.zip\n",
    "  !mkdir /content/pretrain_Q96\n",
    "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
    "  !rm /content/pretrain_Q96.zip\n",
    "\n",
    "if not Path(\"/content/workspace\").exists():\n",
    "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\n",
    "\n",
    "import IPython\n",
    "from google.colab import output\n",
    "\n",
    "display(IPython.display.Javascript('''\n",
    " function ClickConnect(){\n",
    "   btn = document.querySelector(\"colab-connect-button\")\n",
    "   if (btn != null){\n",
    "     console.log(\"Click colab-connect-button\");\n",
    "     btn.click()\n",
    "     }\n",
    "\n",
    "   btn = document.getElementById('ok')\n",
    "   if (btn != null){\n",
    "     console.log(\"Click reconnect\");\n",
    "     btn.click()\n",
    "     }\n",
    "  }\n",
    "\n",
    "setInterval(ClickConnect,60000)\n",
    "'''))\n",
    "\n",
    "print(\"\\nDone!\")"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'DeepFaceLab'...\n",
      "remote: Enumerating objects: 8048, done.\u001B[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001B[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001B[K\n",
      "remote: Total 8048 (delta 0), reused 1 (delta 0), pack-reused 8045\u001B[K\n",
      "Receiving objects: 100% (8048/8048), 828.69 MiB | 27.40 MiB/s, done.\n",
      "Resolving deltas: 100% (5102/5102), done.\n",
      "Updating files: 100% (211/211), done.\n",
      "/content/DeepFaceLab\n",
      "/content\n",
      "Requirement already satisfied: h5py==3.8.0 in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.8.0) (1.25.1)\n",
      "Requirement already satisfied: opencv-python==4.7.0.72 in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.7.0.72) (1.25.1)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0) (0.18.3)\n",
      "Installing collected packages: ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0\n",
      "Collecting colorama==0.4.6\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.6\n",
      "Collecting tf2onnx==1.14.0\n",
      "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m451.2/451.2 kB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx==1.14.0) (1.25.1)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx==1.14.0)\n",
      "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.6/14.6 MB\u001B[0m \u001B[31m79.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx==1.14.0) (2.27.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx==1.14.0) (1.16.0)\n",
      "Collecting flatbuffers<3.0,>=1.12 (from tf2onnx==1.14.0)\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx==1.14.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx==1.14.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx==1.14.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx==1.14.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx==1.14.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx==1.14.0) (3.4)\n",
      "Installing collected packages: flatbuffers, onnx, tf2onnx\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.1 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed flatbuffers-2.0.7 onnx-1.14.0 tf2onnx-1.14.0\n",
      "Downloading Pretrain faceset ... \n",
      "Downloading Q96 pretrained model ...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       " function ClickConnect(){\n",
       "   btn = document.querySelector(\"colab-connect-button\")\n",
       "   if (btn != null){\n",
       "     console.log(\"Click colab-connect-button\");\n",
       "     btn.click()\n",
       "     }\n",
       "\n",
       "   btn = document.getElementById('ok')\n",
       "   if (btn != null){\n",
       "     console.log(\"Click reconnect\");\n",
       "     btn.click()\n",
       "     }\n",
       "  }\n",
       "\n",
       "setInterval(ClickConnect,60000)\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqwOlJG4MdLC"
   },
   "source": [
    "## Manage workspace\n",
    "\n",
    "\n",
    "\n",
    "*   You can import/export workspace or individual data, like model files with Google Drive\n",
    "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
    "*   You can clear all workspace or delete part of it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z4w_sUzgOQmL",
    "cellView": "form",
    "outputId": "61e165d3-c97b-43b4-b861-4d48f715df17",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Import from Drive\n",
    "\n",
    "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
    "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
    "\n",
    "#Mount Google Drive as folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def zip_and_copy(path, mode):\n",
    "  unzip_cmd=\" -q \"+Archive_name\n",
    "\n",
    "  %cd $path\n",
    "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
    "  !cp $copy_cmd\n",
    "  !unzip $unzip_cmd\n",
    "  !rm $Archive_name\n",
    "\n",
    "if Mode == \"workspace\":\n",
    "  zip_and_copy(\"/content\", \"workspace\")\n",
    "elif Mode == \"data_src\":\n",
    "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
    "elif Mode == \"data_dst\":\n",
    "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
    "elif Mode == \"data_src aligned\":\n",
    "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
    "elif Mode == \"data_dst aligned\":\n",
    "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
    "elif Mode == \"models\":\n",
    "  zip_and_copy(\"/content/workspace\", \"model\")\n",
    "\n",
    "print(\"Done!\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content\n",
      "cp: cannot stat '/content/drive/My Drive/workspace.zip': No such file or directory\n",
      "unzip:  cannot find or open workspace.zip, workspace.zip.zip or workspace.zip.ZIP.\n",
      "rm: cannot remove 'workspace.zip': No such file or directory\n",
      "Done!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Y3WfuwoNXqC",
    "cellView": "form",
    "outputId": "86de4a64-fa96-47c0-d1c8-770f3508fbea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Export to Drive { form-width: \"30%\" }\n",
    "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
    "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
    "\n",
    "#Mount Google Drive as folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def zip_and_copy(path, mode):\n",
    "  zip_cmd=\"-0 -r -q \"+Archive_name+\" \"\n",
    "\n",
    "  %cd $path\n",
    "  zip_cmd+=mode\n",
    "  !zip $zip_cmd\n",
    "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
    "  !cp $copy_cmd\n",
    "  !rm $Archive_name\n",
    "\n",
    "if Mode == \"workspace\":\n",
    "  zip_and_copy(\"/content\", \"workspace\")\n",
    "elif Mode == \"data_src\":\n",
    "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
    "elif Mode == \"data_dst\":\n",
    "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
    "elif Mode == \"data_src aligned\":\n",
    "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
    "elif Mode == \"data_dst aligned\":\n",
    "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
    "elif Mode == \"merged\":\n",
    "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
    "elif Mode == \"merged_mask\":\n",
    "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
    "elif Mode == \"models\":\n",
    "  zip_and_copy(\"/content/workspace\", \"model\")\n",
    "elif Mode == \"result video\":\n",
    "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
    "elif Mode == \"result_mask video\":\n",
    "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
    "\n",
    "print(\"Done!\")\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content\n",
      "Done!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0hIvJtxwTGcb",
    "outputId": "4e6c6858-82f3-4cfd-cebf-34b2004e31a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    }
   },
   "source": [
    "#@title Import from URL{ form-width: \"30%\", display-mode: \"form\" }\n",
    "URL = \"http://\" #@param {type:\"string\"}\n",
    "Mode = \"unzip to content\" #@param [\"unzip to content\", \"unzip to content/workspace\", \"unzip to content/workspace/data_src\", \"unzip to content/workspace/data_src/aligned\", \"unzip to content/workspace/data_dst\", \"unzip to content/workspace/data_dst/aligned\", \"unzip to content/workspace/model\", \"download to content/workspace\"]\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "def unzip(zip_path, dest_path):\n",
    "\n",
    "\n",
    "  unzip_cmd = \" unzip -q \" + zip_path + \" -d \"+dest_path\n",
    "  !$unzip_cmd\n",
    "  rm_cmd = \"rm \"+dest_path + url_path.name\n",
    "  !$rm_cmd\n",
    "  print(\"Unziped!\")\n",
    "\n",
    "\n",
    "if Mode == \"unzip to content\":\n",
    "  dest_path = \"/content/\"\n",
    "elif Mode == \"unzip to content/workspace\":\n",
    "  dest_path = \"/content/workspace/\"\n",
    "elif Mode == \"unzip to content/workspace/data_src\":\n",
    "  dest_path = \"/content/workspace/data_src/\"\n",
    "elif Mode == \"unzip to content/workspace/data_src/aligned\":\n",
    "  dest_path = \"/content/workspace/data_src/aligned/\"\n",
    "elif Mode == \"unzip to content/workspace/data_dst\":\n",
    "  dest_path = \"/content/workspace/data_dst/\"\n",
    "elif Mode == \"unzip to content/workspace/data_dst/aligned\":\n",
    "  dest_path = \"/content/workspace/data_dst/aligned/\"\n",
    "elif Mode == \"unzip to content/workspace/model\":\n",
    "  dest_path = \"/content/workspace/model/\"\n",
    "elif Mode == \"download to content/workspace\":\n",
    "  dest_path = \"/content/workspace/\"\n",
    "\n",
    "if not Path(\"/content/workspace\").exists():\n",
    "  cmd = \"mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
    "  !$cmd\n",
    "\n",
    "url_path = Path(URL)\n",
    "urllib.request.urlretrieve ( URL, dest_path + url_path.name )\n",
    "\n",
    "if (url_path.suffix == \".zip\") and (Mode!=\"download to content/workspace\"):\n",
    "  unzip(dest_path + url_path.name, dest_path)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "URLError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-c63931aaa529>\u001B[0m in \u001B[0;36m<cell line: 40>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0murl_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mURL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlretrieve\u001B[0m \u001B[0;34m(\u001B[0m \u001B[0mURL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdest_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0murl_path\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0murl_path\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuffix\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\".zip\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mMode\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0;34m\"download to content/workspace\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/urllib/request.py\u001B[0m in \u001B[0;36murlretrieve\u001B[0;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[1;32m    239\u001B[0m     \u001B[0murl_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_splittype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 241\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mcontextlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclosing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    242\u001B[0m         \u001B[0mheaders\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    243\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/urllib/request.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m         \u001B[0mopener\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 216\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    217\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0minstall_opener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/urllib/request.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    514\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mprocessor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_request\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    515\u001B[0m             \u001B[0mmeth\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocessor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 516\u001B[0;31m             \u001B[0mreq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmeth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    517\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    518\u001B[0m         \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maudit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'urllib.Request'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfull_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/urllib/request.py\u001B[0m in \u001B[0;36mdo_request_\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1270\u001B[0m         \u001B[0mhost\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhost\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1271\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhost\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1272\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mURLError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'no host given'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1273\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1274\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# POST\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error no host given>"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7V1sc7rxNKLO",
    "cellView": "form",
    "outputId": "10af1a53-de32-4ab0-aaa9-43a1503a42c7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Export to URL\n",
    "URL = \"http://\" #@param {type:\"string\"}\n",
    "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
    "\n",
    "cmd_zip = \"zip -0 -r -q \"\n",
    "\n",
    "def run_cmd(zip_path, curl_url):\n",
    "  cmd_zip = \"zip -0 -r -q \"+zip_path\n",
    "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
    "  !$cmd_zip\n",
    "  !$cmd_curl\n",
    "\n",
    "\n",
    "if Mode == \"upload workspace\":\n",
    "  %cd \"/content\"\n",
    "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
    "elif Mode == \"upload data_src\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
    "elif Mode == \"upload data_dst\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
    "elif Mode == \"upload data_src aligned\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
    "elif Mode == \"upload data_dst aligned\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
    "elif Mode == \"upload merged\":\n",
    "  %cd \"/content/workspace/data_dst\"\n",
    "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
    "elif Mode == \"upload model\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
    "elif Mode == \"upload result video\":\n",
    "  %cd \"/content/workspace\"\n",
    "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
    "\n",
    "\n",
    "!rm *.zip\n",
    "\n",
    "%cd \"/content\"\n",
    "print(\"Done!\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "/content\n",
      "Done!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ta6ue_UGMkki",
    "cellView": "form"
   },
   "source": [
    "#@title Delete and recreate\n",
    "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
    "\n",
    "%cd \"/content\"\n",
    "\n",
    "if Mode == \"Delete and recreate workspace\":\n",
    "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
    "elif Mode == \"Delete models\":\n",
    "  cmd = \"rm -r /content/workspace/model/*\"\n",
    "elif Mode == \"Delete data_src\":\n",
    "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
    "elif Mode == \"Delete data_src aligned\":\n",
    "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
    "elif Mode == \"Delete data_src video\":\n",
    "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
    "elif Mode == \"Delete data_dst\":\n",
    "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
    "elif Mode == \"Delete data_dst aligned\":\n",
    "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
    "elif Mode == \"Delete merged frames\":\n",
    "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
    "\n",
    "!$cmd\n",
    "print(\"Done!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUNVcbujhm00"
   },
   "source": [
    "## Extract, sorting and faceset tools\n",
    "* Extract frames for SRC or DST video.\n",
    "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
    "* Detect and align faces. If you need, you can get frames with debug landmarks.\n",
    "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
    "* You can enhance your facesets with DFL FacesetEnhancer.\n",
    "* Resize faceset to your model resolution. Since Colab doesn't have a powerful CPU, resizing samples during training increases iteration time. Faceset resize reduces iteration time by about 2x times. Don't forget to keep save original faceset on your PC.\n",
    "* Pack or unpack facesets with DFL packing tool.\n",
    "* Apply or remove trained XSeg model to the extracted faces.\n",
    "* Recommended for use, Generic XSeg model for auto segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qwJEbz5Nhot0",
    "outputId": "8313c578-5f9b-4ab5-b7ae-102ec596cfea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Extract frames\n",
    "Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "\n",
    "%cd \"/content\"\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" videoed extract-video\"\n",
    "\n",
    "if Video == \"data_dst\":\n",
    "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
    "else:\n",
    "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
    "\n",
    "!python $cmd"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "[0] Enter FPS ( ?:help ) : \n",
      "0\n",
      "[png] Output image format ( png/jpg ?:help ) : \n",
      "png\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    comment         : vid:v0200fg10000cfbj4frc77u8ln22hiig\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:00:44.61, start: 0.000000, bitrate: 310 kb/s\n",
      "    Stream #0:0(und): Video: hevc (Main) (hvc1 / 0x31637668), yuv420p(tv, bt709, progressive), 720x1280, 239 kb/s, SAR 1:1 DAR 9:16, 30 fps, 30 tbr, 15360 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(und): Audio: aac (HE-AACv2) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 64 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (hevc (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to '/content/workspace/data_dst/%5d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    comment         : vid:v0200fg10000cfbj4frc77u8ln22hiig\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: png, rgb24, 720x1280 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.54.100 png\n",
      "frame= 1338 fps= 14 q=-0.0 Lsize=N/A time=00:00:44.60 bitrate=N/A speed=0.464x    \n",
      "video:661977kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "Done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bFmPo0s2lTil",
    "outputId": "cff2cb1b-ae05-4ef5-e0c4-b2664849fece",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Denoise frames\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
    "\n",
    "%cd \"/content\"\n",
    "!python $cmd"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "[7] Denoise factor? ( 1-20 ) : \n",
      "7\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from '/content/workspace/data_dst/%6d.png':\n",
      "  Duration: 00:00:53.52, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 720x1280 [SAR 1:1 DAR 9:16], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 (png) -> hqdn3d\n",
      "  hqdn3d -> Stream #0:0 (png)\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to '/content/workspace/data_dst/%6d.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: png, rgb24, 720x1280 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 png\n",
      "frame= 1338 fps= 12 q=-0.0 Lsize=N/A time=00:00:53.52 bitrate=N/A speed=0.482x    \n",
      "video:493155kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "Done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nmq0Sj2bmq7d",
    "outputId": "c9774b62-04dc-4466-fc03-33556f7a6b18",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#@title Detect faces\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
    "Debug = False #@param {type:\"boolean\"}\n",
    "\n",
    "detect_type = \"s3fd\"\n",
    "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
    "\n",
    "folder = \"workspace/\"+Data\n",
    "folder_aligned = folder+\"/aligned\"\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
    "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
    "\n",
    "if \"whole face\" in Detector:\n",
    "  cmd+=\" --face-type whole_face\"\n",
    "%cd \"/content\"\n",
    "!python $cmd"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "[wf] Face type ( f/wf/head ?:help ) : \n",
      "wf\n",
      "[0] Max number of faces from image ( ?:help ) : \n",
      "0\n",
      "[512] Image size ( 256-2048 ?:help ) : \n",
      "512\n",
      "[90] Jpeg quality ( 1-100 ?:help ) : \n",
      "90\n",
      "Extracting faces...\n",
      "\n",
      "Running on CPU0\n",
      "  0% 0/609 [00:00<?, ?it/s]\n",
      "\n",
      "Error while processing data: Traceback (most recent call last):\n",
      "  File \"/content/DeepFaceLab/core/joblib/SubprocessorBase.py\", line 71, in _subprocess_run\n",
      "    result = self.process_data (data)\n",
      "  File \"/content/DeepFaceLab/mainscripts/Extractor.py\", line 101, in process_data\n",
      "    data = ExtractSubprocessor.Cli.rects_stage (data=data,\n",
      "  File \"/content/DeepFaceLab/mainscripts/Extractor.py\", line 145, in rects_stage\n",
      "    rects = data.rects = rects_extractor.extract (rotated_image, is_bgr=True)\n",
      "  File \"/content/DeepFaceLab/facelib/S3FDExtractor.py\", line 196, in extract\n",
      "    for ltrb in self.refine (olist):\n",
      "  File \"/content/DeepFaceLab/facelib/S3FDExtractor.py\", line 245, in refine\n",
      "    bboxlist = [ x[:-1].astype(np.int) for x in bboxlist if x[-1] >= 0.5]\n",
      "  File \"/content/DeepFaceLab/facelib/S3FDExtractor.py\", line 245, in <listcomp>\n",
      "    bboxlist = [ x[:-1].astype(np.int) for x in bboxlist if x[-1] >= 0.5]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\", line 313, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'int'.\n",
      "`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "  0% 0/609 [00:05<?, ?it/s]\n",
      "-------------------------\n",
      "Images found:        609\n",
      "Faces detected:      0\n",
      "-------------------------\n",
      "Done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TRNxUFE6p6Eu"
   },
   "source": [
    "#@title Sort aligned\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "sort_type = \"hist\" #@param [\"blur\", \"motion-blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final-by-blur\", \"final-by-size\", \"absdiff\"]\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
    "\n",
    "%cd \"/content\"\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O5MbnVDyXkP7"
   },
   "source": [
    "#@title Faceset Enhancer\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "\n",
    "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
    "cmd = decrypt_text(\"L2NvbnRlbnQvRGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" facesettool enhance --input-dir \"+data_path\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hyg5SREuMx8Q"
   },
   "source": [
    "#@title Resize faceset\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "\n",
    "cmd = decrypt_text(\"L2NvbnRlbnQvRGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" facesettool resize --input-dir /content/workspace/\" + \\\n",
    "      f\"{Data}/aligned\"\n",
    "\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ypLfPUNHZNEp"
   },
   "source": [
    "#@title Pack/Unpack aligned faceset\n",
    "\n",
    "Folder = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "Mode = \"unpack\" #@param [\"pack\", \"unpack\"]\n",
    "\n",
    "cmd = decrypt_text(\"L2NvbnRlbnQvRGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" util --input-dir /content/workspace/\" + \\\n",
    "      f\"{Folder}/aligned --{Mode}-faceset\"\n",
    "\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-VVvtoBMGnrA"
   },
   "source": [
    "#@title Apply or remove XSeg mask to the faces\n",
    "Mode = \"Apply mask\" #@param [\"Apply mask\", \"Remove mask\"]\n",
    "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
    "GenericXSeg = True #@param {type:\"boolean\"}\n",
    "\n",
    "from pathlib import Path\n",
    "mode_arg = 'apply' if Mode == \"Apply mask\" else 'remove'\n",
    "\n",
    "if GenericXSeg and not Path('/content/GenericXSeg').exists():\n",
    "  print('Downloading Generic XSeg model ... ')\n",
    "  xseg_link = decrypt_text(\"aHR0cHM6Ly9naXRodWIuY29tL2NoZXJ2b25pai9ERkwtQ29sYWIvcmVsZWFzZXMvZG93bmxvYWQvR2VuZXJpY1hTZWcvR2VuZXJpY1hTZWcuemlw\")\n",
    "  !mkdir /content/GenericXSeg\n",
    "  !wget -q --no-check-certificate -r $xseg_link -O /content/GenericXSeg.zip\n",
    "  !unzip -q /content/GenericXSeg.zip -d /content/GenericXSeg/\n",
    "  !rm /content/GenericXSeg.zip\n",
    "\n",
    "main_path = decrypt_text(\"L2NvbnRlbnQvRGVlcEZhY2VMYWIvbWFpbi5weQ==\")\n",
    "data_path = f'/content/workspace/{Data}/aligned'\n",
    "model_path = '/content/workspace/model' if not GenericXSeg else '/content/GenericXSeg'\n",
    "\n",
    "cmd = f'{main_path} xseg {mode_arg} --input-dir {data_path} '\n",
    "cmd += f'--model-dir {model_path}' if mode_arg == 'apply' else ''\n",
    "\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTuyUxgdLA13"
   },
   "source": [
    "## Train model\n",
    "\n",
    "* Choose your model type, but SAEHD is recommend for everyone\n",
    "* Set model options on output field\n",
    "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
    "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
    "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
    "* Also, you can export your workspace manually in \"Manage workspace\" block\n",
    "* \"Silent_Start\" option provides to automatically start with best GPU and last used model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z0Kya-PJLDhv"
   },
   "source": [
    "#@title Training\n",
    "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"Quick96\", \"XSeg\"]\n",
    "Backup_every_hour = True #@param {type:\"boolean\"}\n",
    "Silent_Start = True #@param {type:\"boolean\"}\n",
    "\n",
    "%cd \"/content\"\n",
    "\n",
    "#Mount Google Drive as folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import psutil, os, time\n",
    "\n",
    "p = psutil.Process(os.getpid())\n",
    "uptime = time.time() - p.create_time()\n",
    "\n",
    "if (Backup_every_hour):\n",
    "  if not os.path.exists('workspace.zip'):\n",
    "    print(\"Creating workspace archive ...\")\n",
    "    !zip -0 -r -q workspace.zip workspace\n",
    "    print(\"Archive created!\")\n",
    "  else:\n",
    "    print(\"Archive exist!\")\n",
    "\n",
    "if (Backup_every_hour):\n",
    "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
    "  backup_time = str(3600)\n",
    "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\"\n",
    "elif (round(39600-uptime) > 0):\n",
    "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
    "  backup_time = str(round(39600-uptime))\n",
    "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -0 -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\"\n",
    "else:\n",
    "  print(\"Session expires in less than an hour.\")\n",
    "  backup_cmd = \"\"\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain --model-dir workspace/model --model \"+Model\n",
    "\n",
    "if Model == \"Quick96\":\n",
    "  cmd+= \" --pretrained-model-dir pretrain_Q96\"\n",
    "\n",
    "if Silent_Start:\n",
    "  cmd+= \" --silent-start\"\n",
    "\n",
    "if (backup_cmd != \"\"):\n",
    "  train_cmd = (cmd+backup_cmd)\n",
    "else:\n",
    "  train_cmd = (cmd)\n",
    "\n",
    "!python $train_cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avAcSL_uvtq_"
   },
   "source": [
    "## Merge frames"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A3Y8K22Sv9Gn"
   },
   "source": [
    "#@title Merge\n",
    "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"Quick96\" ]\n",
    "\n",
    "cmd = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\") + \" merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
    "\n",
    "%cd \"/content\"\n",
    "!python $cmd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JNeGfiZpxlnz"
   },
   "source": [
    "#@title Get result video\n",
    "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
    "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "if Mode == \"result video\":\n",
    "  tmp = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\")\n",
    "  !python $tmp videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio\n",
    "  if Copy_to_Drive:\n",
    "    !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
    "elif Mode == \"result_mask video\":\n",
    "  tmp = decrypt_text(\"RGVlcEZhY2VMYWIvbWFpbi5weQ==\")\n",
    "  !python $tmp videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4\n",
    "  if Copy_to_Drive:\n",
    "    !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}